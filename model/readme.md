# Purpose

To implement the customer support function for the course project.

This AI system is used in the customer support module to provide real-time responses to users.  
The AI dialogue system leverages a large language model combined with RAG (Retrieval-Augmented Generation) technology to enable intelligent question answering.  
It utilizes the Qwen-max model, enhanced with prompt engineering to improve response quality.  
**Knowledge base construction**: System function descriptions in tabular form are segmented using a recursive chunking strategy, and embedded using a language model to build a Chroma vector database.  
**RAG workflow**: A hypothetical answer is generated using the HyDE method and used as a query. The hypothetical answer is vectorized and average pooled, then matched against the vector database. The top 3 most relevant texts are retrieved based on cosine similarity, and the final response is generated by the large language model after ranking.

# API

**Endpoint**: `http://119.45.26.22:3389/qwen`

**Method**: `POST`

**Content-Type**: `application/json`

**Response Type**: `text/event-stream` (supports streaming responses)

| Parameter Name | Type   | Description                    |
| -------------- | ------ | ------------------------------ |
| `uid`          | string | User ID                        |
| `cid`          | string | Conversation ID                |
| `status`       | int    | Status code (fixed to 0)       |
| `query`        | string | Current user query             |
| `history_chat` | list   | Chat history (empty list here) |

`history_chat` represents the conversation history, arranged in alternating question-answer format. The length should be even.

For example:

User: Hello  
AI: Hello  
User: Who are you?  
AI: I am AI  

Then:

```json
history_chat = ["Hello", "Hello", "Who are you?", "I am AI"]
```

Pass only the last 10 entries of the latest conversation. It is recommended to set this as a configurable parameter.

`query` is the current question:

User: Hello
 AI: Hello
 User: Who are you?
 AI: I am AI
 User: "Oh"

Then “Oh” is the current query:

```json
query = "Oh"
```

## Response (Streaming)

```json
{
  "status": int,
  "uid": str,
  "cid": str,
  "answer": str
}
```

Actual return:

```python
data: {"status": int, "uid": str, "cid": str, "answer": str}\n\n
```
